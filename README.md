# Generated Data with Fake Privacy: Hidden Dangers of Fine-tuning Large Language Models on Generated Data

> Large language models (LLMs) have demonstrated significant success in various domain-specific tasks, with their performance often improving substantially after fine-tuning. However, fine-tuning with real-world data introduces privacy risks. To mitigate these risks, developers increasingly rely on synthetic data generation as an alternative to using real data, as data generated by traditional models is believed to be different from real-world data. However, with the advanced capabilities of LLMs, the distinction between real data and data generated by these models has become nearly indistinguishable. This convergence introduces similar privacy risks for generated data to those associated with real data. In this paper, we present an empirical analysis of this underexplored issue by investigating a key question: "Does fine-tuning with LLM-generated data enhance privacy, or does it pose additional privacy risks?" Our study investigates this question by examining the structural characteristics of data generated by LLMs, focusing on two primary fine-tuning approaches: supervised fine-tuning (SFT) with unstructured (plain-text) generated data and self-instruct tuning. In the scenario of SFT, the data is put into a particular instruction tuning format used by previous studies. We use Personal Information Identifier (PII) leakage and Membership Inference Attacks (MIAs) on the Pythia Model Suite and Open Pre-trained Transformer (OPT) to measure privacy risks. Notably, after fine-tuning with unstructured generated data, the rate of successful PII extractions for Pythia increased by over 20%, highlighting the potential privacy implications of such approaches. Furthermore, the ROC-AUC score of MIAs for Pythia-6.9b, the second biggest model of the suite, increases over 40%  after self-instruct tuning. 
Our results indicate the potential privacy risks associated with fine-tuning LLMs using generated data, underscoring the need for careful consideration of privacy safeguards in such approaches.

<!-- > **Keywords**: <a href="https://en.wikipedia.org/wiki/thing" target="_blank">**RSomething**</a>. -->



---

## Table of Contents 

> **Note**: This framework is open for academic use but requires licensing for commercial use. Please refer to the [License](#license) section for more details.

- [Important Notes](#important-notes)
- [Installation](#installation)
- [Data](#data)
- [Instructions Manual](#instructions-manual)
- [Citations](#citations)
- [License](#license)

---
## Important Notes
### Ethics Consideration for Model Checkpoints

Due to ethical considerations, we have not provided the model checkpoints in the public repository. If you need a checkpoint for academic purposes, please contact us. We can provide a checkpoint strictly for academic use.

**Contact**: sinem.sav@cs.bilkent.edu.tr, m.poorghaffar@bilkent.edu.tr

---
## Installation

The dependencies and requirements are listed on `requirements.txt`. 

### Requirements

To set up the project environment, ensure you have **Python 3.10 or newer** installed. Then, follow these steps:

1. Prepare your environment (Virtual or Conda). We suggest using pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime docker image.
2. Install the dependencies using `requirements.txt` as follows:

```shell
cd /path/to/repo
pip install -r requirements.txt
```
---
## Data

### Datasets and Files

- **`data/enron.jsonl`**: Original Enron dataset from PIL.
- **`data/original_data.arrow`**: Dataset generated by `Pythia12b` using the original Enron dataset.
- **`data/replaced_data.arrow`**: Similar to `original_data.arrow`, but with names and emails in the Enron dataset replaced.
- **`data/seedTasks.json`**: Seed tasks used for self-instruct tasks.
---

## Instructions Manual

### Fine-Tuning Models with PEFT (`run_peft.py`)  
> **Important**: Run the script `run_peft.py` to fine-tune the models with PEFT (Parameter-Efficient Fine-Tuning).  

#### **Suggested Execution**  
It is recommended to execute the script using `torchrun` for distributed training, which automatically handles the environment variables required for distributed execution.  

Alternatively, if you run the script directly, you must manually set the following environment variables:  
- `MASTER_ADDR`: The address of the master node (e.g., `"localhost"`).  
- `MASTER_PORT`: The port for communication (e.g., `29500`).  
- `WORLD_SIZE`: The total number of processes participating in the distributed training.  

For example:  
```bash  
MASTER_ADDR=localhost MASTER_PORT=29500 WORLD_SIZE=4 python run_peft.py --model EleutherAI/pythia-1.4b
```
#### Key Arguments

- `-m`, `--model`: Specifies the model to be instruction-tuned.  
  **Default**: `"EleutherAI/pythia-1.4b"`

- `-i`, `--input`: Path to the training dataset.  
  **Default**: `"./data/enron.jsonl"`

- `-pdbs`, `--per_device_batch_size`: The batch size per device.  
  **Default**: `1`

- `-gas`, `--gradient_accumulation_steps`: Number of gradient accumulation steps.  
  **Default**: `8`

- `-w`, `--warmup_steps`: Number of warmup steps for learning rate scheduling.  
  **Default**: `0`

- `-e`, `--epochs`: Total number of training epochs.  
  **Default**: `4`

- `-lr`, `--learning_rate`: Learning rate for training.  
  **Default**: `2e-6`

- `-l`, `--logging_steps`: Number of steps between logging outputs.  
  **Default**: `1`

- `-opt`, `--optimizer`: Optimizer to use for training.  
  **Default**: `"adamw_torch"`

- `-wd`, `--weight_decay`: Weight decay value for regularization.  
  **Default**: `0`

- `-s`, `--scheduler`: Learning rate scheduler to use.  
  **Default**: `"linear"`

- `-dt`, `--distribution_type`: Specifies the distribution type. Options: `ddp`, `mp`, or `fsdp`.  
  **Default**: `"ddp"`

- `-pt`, `--peft_type`: Specifies the PEFT type. Options: `lora`, `dora`, or `pissa`.  
  **Default**: `"lora"`


### Merging Adapters with PEFT (`merge_peft.py`)
> **Important**: Use the script `merge_peft.py` to merge the adapter results obtained from fine-tuning.

#### Key Arguments

- `--model`: Path to the fine-tuned model to be merged, like the output path of the above run_peft.py for the adapters. 
  **Required**

- `--save_dir`: Directory to save the merged model.  
  **Default**: `"./tempMerged"`

- `--is_opt`: Flag to indicate if the model is an OPT variant.  
  **Default**: `False`

### Measuring PII Attack Success (`measure_purified.py`)
> **Important**: Use the script `measure_purified.py` to evaluate the successful number of PII (Personally Identifiable Information) attacks.  
> The script generates a `results_purified.jsonl` file in each model's directory, containing the fields: `[matches, model, temperature, top_k]`.

#### Key Arguments

- `model`: Name of the model to be evaluated.  
  **Required**

- `output_dir`: Directory where the `results.txt` file will be saved.  
  **Required**

- `--top_k`: Specifies the top K values for evaluation.  
  **Default**: `100`

- `-mt`, `--max_tokens`: Maximum number of tokens for evaluation.  
  **Default**: `15`

- `-d`, `--dataset`: Path to the dataset used for evaluation.  
  **Default**: `"./data/enron.jsonl"`


### Evaluating Models with Purified Workflow (`evaluate_purified.py`)
> **Important**: Use the script `evaluate_purified.py` to run `merge_peft.py` and `measure_purified.py` sequentially for all models in a specified directory.

#### Key Arguments

- `-m`, `--model`: Path to the model to be evaluated.  
  **Default**: `"./pythia-1.4b"`

- `-t`, `--temp`: Temporary storage directory where the adapter and base model will be merged.  
  **Default**: `"./tempMerged"`

- `-d`, `--dataset`: Path to the dataset used for evaluation.  
  **Default**: `"./data/enron.jsonl"`

- `--is_opt`: Flag to indicate if the model is an OPT variant.  
  **Default**: `False`

### Measuring Model Perplexity (`perplexity/perplexity.py`)
> **Important**: Use the script `perplexity/perplexity.py` to calculate the perplexity of models in a directory.  
> The script generates a `perplexity.txt` file, containing perplexity information for each checkpoint.

#### Key Arguments

- `--dir`: Directory containing the models to be evaluated.  
  **Default**: `"./pythia-1.4b"`

- `-d`, `--dataset`: Path to the dataset used for calculating perplexity.  
  **Default**: `"./data/enron.jsonl"`

### Generating Continuation Data (`data/continuation/generate.py`)
> **Important**: Use the script `data/continuation/generate.py` to generate continuation data using a specified model and dataset. After that, you can use the run_peft.py with the generated data for self-instruction tuning.

#### Key Arguments

- `-m`, `--model`: Name of the model to be used for generating continuation data.  
  **Default**: `"EleutherAI/pythia-12b"`

- `--top_k`: Specifies the top K values for generation.  
  **Default**: `100`

- `-mt`, `--max_tokens`: Maximum number of tokens to generate.  
  **Default**: `1000`

- `-d`, `--data_set`: Path to the dataset used for generation.  
  **Default**: `"./data/enron.jsonl"`

---

## Citations

---

## License

- **[CC BY-NC-SA 2.0](https://creativecommons.org/licenses/by-nc-sa/2.0/)**
- Â© 2025 Generated Data with Fake Privacy.
- **For commercial use, please contact.**
